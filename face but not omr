import cv2
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model
from deepface import DeepFace
from google.colab import files
from sklearn.preprocessing import LabelEncoder
import pickle

# Upload model and label encoder
model_path = "face_recognition_model_2.keras"
label_encoder_path = "label_encoder.pkl"

# Load the trained model
model = load_model(model_path)
with open(label_encoder_path, "rb") as f:
    label_encoder = pickle.load(f)

# Upload the OMR sheet
uploaded = files.upload()
omr_sheet_path = list(uploaded.keys())[0]

# Extract candidate face from top-left corner (entire top-left region)
def extract_face(image_path):
    image = cv2.imread(image_path)
    height, width = image.shape[:2]
    face_crop = image[0:int(height * 0.15), int(width*0.05):int(width * 0.22)]  # Take top-left 20% of height, 30% of width
    face_path = "temp_face.jpg"
    cv2.imwrite(face_path, face_crop)
    return face_path

# Predict candidate identity
def predict_identity(face_path):
    embedding_list = DeepFace.represent(img_path=face_path, model_name="Facenet", enforce_detection=False)
    if embedding_list:
        embedding = embedding_list[0]['embedding']
        embedding = np.array(embedding).reshape(1, -1)
        prediction = model.predict(embedding)
        predicted_label_index = np.argmax(prediction)
        confidence = prediction[0][predicted_label_index]
        if confidence > 0.5:
            return label_encoder.inverse_transform([predicted_label_index])[0]
    return "Unknown"

# OMR Processing
answer_key = {1: 0, 2: 1, 3: 2, 4: 3, 5: 2, 6: 1, 7: 0, 8: 1, 9: 2, 10: 3}

def preprocess_image(image_path):
    image = cv2.imread(image_path)
    if image is None:
        raise ValueError(f"Error loading image: {image_path}")

    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    thresh = cv2.threshold(blurred, 150, 255, cv2.THRESH_BINARY_INV)[1]
    return image, thresh

def detect_bubbles(thresh):
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    bubble_contours = [c for c in contours if 100 < cv2.contourArea(c) < 1000]

    bubble_contours = sorted(bubble_contours, key=lambda c: (cv2.boundingRect(c)[1], cv2.boundingRect(c)[0]))

    questions = [bubble_contours[i:i+4] for i in range(0, len(bubble_contours), 4)][:10]

    return questions

def identify_filled_bubbles(thresh, questions):
    filled_bubbles = {}

    for q_index, options in enumerate(questions, start=1):
        filled = -1
        max_intensity = 0

        for opt_index, contour in enumerate(options):
            x, y, w, h = cv2.boundingRect(contour)
            roi = thresh[y:y+h, x:x+w]
            filled_ratio = cv2.countNonZero(roi) / (w * h)

            if filled_ratio > 0.5 and filled_ratio > max_intensity:
                max_intensity = filled_ratio
                filled = opt_index

        filled_bubbles[q_index] = filled

    return filled_bubbles

def grade_omr(filled_bubbles, answer_key):
    score = 0
    for q_num, correct_ans in answer_key.items():
        if filled_bubbles.get(q_num, -1) == correct_ans:
            score += 1
    return score

def process_omr(image_path, answer_key):
    image, thresh = preprocess_image(image_path)
    questions = detect_bubbles(thresh)
    filled_bubbles = identify_filled_bubbles(thresh, questions)
    score = grade_omr(filled_bubbles, answer_key)
    return filled_bubbles, score

# Run the pipeline
face_path = extract_face(omr_sheet_path)
candidate_name = predict_identity(face_path)
filled_bubbles, score = process_omr(omr_sheet_path, answer_key)

print(f"Candidate: {candidate_name}")
print(f"Detected Answers: {filled_bubbles}")
print(f"Score: {score}/{len(answer_key)}")

# Display the OMR sheet
plt.imshow(cv2.cvtColor(cv2.imread(omr_sheet_path), cv2.COLOR_BGR2RGB))
plt.axis('off')
plt.show()
